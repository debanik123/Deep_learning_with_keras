{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"input/data.csv\")\n",
    "del data[\"Unnamed: 32\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,2:].values\n",
    "y = data.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train =sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \n",
      "C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \"\"\"\n",
      "C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(output_dim = 16,init=\"uniform\",activation=\"relu\",input_dim=30))\n",
    "model.add(Dropout(p=0.1))\n",
    "\n",
    "model.add(Dense(output_dim =16, init=\"uniform\",activation=\"relu\"))\n",
    "model.add(Dropout(p=0.1))\n",
    "\n",
    "model.add(Dense(output_dim=1, init=\"uniform\",activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 0.6925 - acc: 0.6836\n",
      "Epoch 2/150\n",
      "512/512 [==============================] - 0s 64us/step - loss: 0.6904 - acc: 0.7324\n",
      "Epoch 3/150\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.6865 - acc: 0.8047\n",
      "Epoch 4/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.6805 - acc: 0.8770\n",
      "Epoch 5/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.6714 - acc: 0.9238\n",
      "Epoch 6/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.6564 - acc: 0.9277\n",
      "Epoch 7/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.6349 - acc: 0.9316\n",
      "Epoch 8/150\n",
      "512/512 [==============================] - 0s 56us/step - loss: 0.6081 - acc: 0.9375\n",
      "Epoch 9/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.5685 - acc: 0.9395\n",
      "Epoch 10/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.5251 - acc: 0.9414\n",
      "Epoch 11/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.4754 - acc: 0.9512\n",
      "Epoch 12/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.4262 - acc: 0.9453\n",
      "Epoch 13/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3721 - acc: 0.9531\n",
      "Epoch 14/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.3261 - acc: 0.9551\n",
      "Epoch 15/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.2796 - acc: 0.9609\n",
      "Epoch 16/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.2513 - acc: 0.9609\n",
      "Epoch 17/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.2176 - acc: 0.9668\n",
      "Epoch 18/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.1925 - acc: 0.9629\n",
      "Epoch 19/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.1738 - acc: 0.9648\n",
      "Epoch 20/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.1593 - acc: 0.9687\n",
      "Epoch 21/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.1418 - acc: 0.9687\n",
      "Epoch 22/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.1304 - acc: 0.9688\n",
      "Epoch 23/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.1240 - acc: 0.9727\n",
      "Epoch 24/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.1203 - acc: 0.9727\n",
      "Epoch 25/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.1085 - acc: 0.9746\n",
      "Epoch 26/150\n",
      "512/512 [==============================] - 0s 29us/step - loss: 0.1032 - acc: 0.9746\n",
      "Epoch 27/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0989 - acc: 0.9785\n",
      "Epoch 28/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0960 - acc: 0.9746\n",
      "Epoch 29/150\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0923 - acc: 0.9785\n",
      "Epoch 30/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0916 - acc: 0.9766\n",
      "Epoch 31/150\n",
      "512/512 [==============================] - 0s 30us/step - loss: 0.0888 - acc: 0.9824\n",
      "Epoch 32/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0837 - acc: 0.9844\n",
      "Epoch 33/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0827 - acc: 0.9824\n",
      "Epoch 34/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.0813 - acc: 0.9805\n",
      "Epoch 35/150\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.0644 - acc: 0.990 - 0s 33us/step - loss: 0.0804 - acc: 0.9805\n",
      "Epoch 36/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0748 - acc: 0.9844\n",
      "Epoch 37/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0762 - acc: 0.9824\n",
      "Epoch 38/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.0693 - acc: 0.9824\n",
      "Epoch 39/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0752 - acc: 0.9824\n",
      "Epoch 40/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0735 - acc: 0.9824\n",
      "Epoch 41/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0701 - acc: 0.9844\n",
      "Epoch 42/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0703 - acc: 0.9824\n",
      "Epoch 43/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0698 - acc: 0.9805\n",
      "Epoch 44/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0678 - acc: 0.9844\n",
      "Epoch 45/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.0681 - acc: 0.9844\n",
      "Epoch 46/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0676 - acc: 0.9863\n",
      "Epoch 47/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0668 - acc: 0.9863\n",
      "Epoch 48/150\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.0641 - acc: 0.9844\n",
      "Epoch 49/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0636 - acc: 0.9844\n",
      "Epoch 50/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0644 - acc: 0.9863\n",
      "Epoch 51/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.0661 - acc: 0.9863\n",
      "Epoch 52/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0624 - acc: 0.9844\n",
      "Epoch 53/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.0613 - acc: 0.9844\n",
      "Epoch 54/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.0621 - acc: 0.9844\n",
      "Epoch 55/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0650 - acc: 0.9824\n",
      "Epoch 56/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0603 - acc: 0.9844\n",
      "Epoch 57/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0644 - acc: 0.9824\n",
      "Epoch 58/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0575 - acc: 0.9844\n",
      "Epoch 59/150\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0623 - acc: 0.9844\n",
      "Epoch 60/150\n",
      "512/512 [==============================] - 0s 28us/step - loss: 0.0570 - acc: 0.9844\n",
      "Epoch 61/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0555 - acc: 0.9844\n",
      "Epoch 62/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0591 - acc: 0.9844\n",
      "Epoch 63/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0558 - acc: 0.9844\n",
      "Epoch 64/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0536 - acc: 0.9863\n",
      "Epoch 65/150\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0594 - acc: 0.9824\n",
      "Epoch 66/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0564 - acc: 0.9844\n",
      "Epoch 67/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0547 - acc: 0.9844\n",
      "Epoch 68/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0558 - acc: 0.9844\n",
      "Epoch 69/150\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0501 - acc: 0.9844\n",
      "Epoch 70/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0547 - acc: 0.9844\n",
      "Epoch 71/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0554 - acc: 0.9863\n",
      "Epoch 72/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0519 - acc: 0.9863\n",
      "Epoch 73/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.0466 - acc: 0.9844\n",
      "Epoch 74/150\n",
      "512/512 [==============================] - 0s 29us/step - loss: 0.0578 - acc: 0.9844\n",
      "Epoch 75/150\n",
      "512/512 [==============================] - 0s 41us/step - loss: 0.0525 - acc: 0.9844\n",
      "Epoch 76/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0535 - acc: 0.9863\n",
      "Epoch 77/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.0548 - acc: 0.9863\n",
      "Epoch 78/150\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0497 - acc: 0.9863\n",
      "Epoch 79/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.0484 - acc: 0.9883\n",
      "Epoch 80/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.0481 - acc: 0.9883\n",
      "Epoch 81/150\n",
      "512/512 [==============================] - 0s 30us/step - loss: 0.0476 - acc: 0.9883\n",
      "Epoch 82/150\n",
      "512/512 [==============================] - 0s 26us/step - loss: 0.0515 - acc: 0.9883\n",
      "Epoch 83/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0514 - acc: 0.9902\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 0s 30us/step - loss: 0.0531 - acc: 0.9883\n",
      "Epoch 85/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0479 - acc: 0.9883\n",
      "Epoch 86/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0479 - acc: 0.9883\n",
      "Epoch 87/150\n",
      "512/512 [==============================] - 0s 23us/step - loss: 0.0486 - acc: 0.9863\n",
      "Epoch 88/150\n",
      "512/512 [==============================] - 0s 29us/step - loss: 0.0487 - acc: 0.9902\n",
      "Epoch 89/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.0454 - acc: 0.9902\n",
      "Epoch 90/150\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.0859 - acc: 0.980 - 0s 37us/step - loss: 0.0553 - acc: 0.9883\n",
      "Epoch 91/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0524 - acc: 0.9863\n",
      "Epoch 92/150\n",
      "512/512 [==============================] - 0s 47us/step - loss: 0.0468 - acc: 0.9883\n",
      "Epoch 93/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.0468 - acc: 0.9883\n",
      "Epoch 94/150\n",
      "512/512 [==============================] - 0s 50us/step - loss: 0.0476 - acc: 0.9902\n",
      "Epoch 95/150\n",
      "512/512 [==============================] - 0s 53us/step - loss: 0.0445 - acc: 0.9863\n",
      "Epoch 96/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0483 - acc: 0.9863\n",
      "Epoch 97/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0489 - acc: 0.9883\n",
      "Epoch 98/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0453 - acc: 0.9883\n",
      "Epoch 99/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0485 - acc: 0.9883\n",
      "Epoch 100/150\n",
      "512/512 [==============================] - 0s 60us/step - loss: 0.0442 - acc: 0.9902\n",
      "Epoch 101/150\n",
      "512/512 [==============================] - 0s 52us/step - loss: 0.0431 - acc: 0.9883\n",
      "Epoch 102/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0473 - acc: 0.9863\n",
      "Epoch 103/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0461 - acc: 0.9883\n",
      "Epoch 104/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0441 - acc: 0.9883\n",
      "Epoch 105/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0492 - acc: 0.9902\n",
      "Epoch 106/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0451 - acc: 0.9902\n",
      "Epoch 107/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0430 - acc: 0.9902\n",
      "Epoch 108/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.0368 - acc: 0.9902\n",
      "Epoch 109/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0451 - acc: 0.9883\n",
      "Epoch 110/150\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0468 - acc: 0.9902\n",
      "Epoch 111/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0411 - acc: 0.9922\n",
      "Epoch 112/150\n",
      "512/512 [==============================] - 0s 45us/step - loss: 0.0417 - acc: 0.9922\n",
      "Epoch 113/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0454 - acc: 0.9922\n",
      "Epoch 114/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0426 - acc: 0.9922\n",
      "Epoch 115/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.0399 - acc: 0.9922\n",
      "Epoch 116/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.0466 - acc: 0.9922\n",
      "Epoch 117/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0464 - acc: 0.9902\n",
      "Epoch 118/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0385 - acc: 0.9922\n",
      "Epoch 119/150\n",
      "512/512 [==============================] - 0s 35us/step - loss: 0.0403 - acc: 0.9902\n",
      "Epoch 120/150\n",
      "512/512 [==============================] - 0s 38us/step - loss: 0.0407 - acc: 0.9902\n",
      "Epoch 121/150\n",
      "512/512 [==============================] - 0s 46us/step - loss: 0.0415 - acc: 0.9922\n",
      "Epoch 122/150\n",
      "512/512 [==============================] - 0s 31us/step - loss: 0.0404 - acc: 0.9922\n",
      "Epoch 123/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0431 - acc: 0.9902\n",
      "Epoch 124/150\n",
      "512/512 [==============================] - 0s 44us/step - loss: 0.0446 - acc: 0.9922\n",
      "Epoch 125/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0384 - acc: 0.9922\n",
      "Epoch 126/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.0427 - acc: 0.9902\n",
      "Epoch 127/150\n",
      "512/512 [==============================] - 0s 30us/step - loss: 0.0421 - acc: 0.9922\n",
      "Epoch 128/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0398 - acc: 0.9922\n",
      "Epoch 129/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0414 - acc: 0.9922\n",
      "Epoch 130/150\n",
      "512/512 [==============================] - 0s 42us/step - loss: 0.0414 - acc: 0.9902\n",
      "Epoch 131/150\n",
      "512/512 [==============================] - 0s 39us/step - loss: 0.0423 - acc: 0.9883\n",
      "Epoch 132/150\n",
      "512/512 [==============================] - 0s 30us/step - loss: 0.0351 - acc: 0.9922\n",
      "Epoch 133/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.0411 - acc: 0.9902\n",
      "Epoch 134/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0374 - acc: 0.9922\n",
      "Epoch 135/150\n",
      "512/512 [==============================] - 0s 43us/step - loss: 0.0416 - acc: 0.9922\n",
      "Epoch 136/150\n",
      "512/512 [==============================] - ETA: 0s - loss: 0.0184 - acc: 1.000 - 0s 38us/step - loss: 0.0402 - acc: 0.9922\n",
      "Epoch 137/150\n",
      "512/512 [==============================] - 0s 34us/step - loss: 0.0445 - acc: 0.9902\n",
      "Epoch 138/150\n",
      "512/512 [==============================] - 0s 28us/step - loss: 0.0351 - acc: 0.9922\n",
      "Epoch 139/150\n",
      "512/512 [==============================] - 0s 29us/step - loss: 0.0375 - acc: 0.9922\n",
      "Epoch 140/150\n",
      "512/512 [==============================] - 0s 37us/step - loss: 0.0395 - acc: 0.9922\n",
      "Epoch 141/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.0390 - acc: 0.9922\n",
      "Epoch 142/150\n",
      "512/512 [==============================] - 0s 29us/step - loss: 0.0398 - acc: 0.9902\n",
      "Epoch 143/150\n",
      "512/512 [==============================] - 0s 28us/step - loss: 0.0397 - acc: 0.9922\n",
      "Epoch 144/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0365 - acc: 0.9922\n",
      "Epoch 145/150\n",
      "512/512 [==============================] - 0s 32us/step - loss: 0.0408 - acc: 0.9902\n",
      "Epoch 146/150\n",
      "512/512 [==============================] - 0s 48us/step - loss: 0.0410 - acc: 0.9902\n",
      "Epoch 147/150\n",
      "512/512 [==============================] - 0s 28us/step - loss: 0.0420 - acc: 0.9902\n",
      "Epoch 148/150\n",
      "512/512 [==============================] - 0s 40us/step - loss: 0.0428 - acc: 0.9883\n",
      "Epoch 149/150\n",
      "512/512 [==============================] - 0s 36us/step - loss: 0.0423 - acc: 0.9902\n",
      "Epoch 150/150\n",
      "512/512 [==============================] - 0s 33us/step - loss: 0.0387 - acc: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13372c640b8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=100,nb_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy is 94.73684210526315%\n"
     ]
    }
   ],
   "source": [
    "print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1])/57)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig(\"h.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
