{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.random((1000,20))\n",
    "y_train = np.random.randint(2,size=(1000,1))\n",
    "\n",
    "x_test = np.random.random((100,20))\n",
    "y_test = np.random.randint(2,size=(100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(64,input_dim=20,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Debanik Roy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s 817us/step - loss: 0.7507 - acc: 0.4900\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.7168 - acc: 0.5050\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.7194 - acc: 0.4820\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.7119 - acc: 0.4940\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.7071 - acc: 0.4950\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6937 - acc: 0.5240\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.7061 - acc: 0.4990\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.7018 - acc: 0.4900\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.7010 - acc: 0.5090\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.7000 - acc: 0.4860\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 0.6962 - acc: 0.5110\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.6966 - acc: 0.5010\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6955 - acc: 0.5180\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6941 - acc: 0.5010\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6897 - acc: 0.5130\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.6923 - acc: 0.5090\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6925 - acc: 0.5140\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6858 - acc: 0.5490\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6953 - acc: 0.5220\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6836 - acc: 0.625 - 0s 49us/step - loss: 0.6924 - acc: 0.5330\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 45us/step - loss: 0.6903 - acc: 0.5330\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6917 - acc: 0.5280\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6965 - acc: 0.5060\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.6924 - acc: 0.5270\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.6882 - acc: 0.5310\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6936 - acc: 0.5090\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 0.6933 - acc: 0.5030\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6911 - acc: 0.5400\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6889 - acc: 0.5380\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.6910 - acc: 0.5420\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6893 - acc: 0.5230\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6906 - acc: 0.5300\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6907 - acc: 0.5480\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6925 - acc: 0.4990\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6884 - acc: 0.5410\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.6870 - acc: 0.5350\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6872 - acc: 0.5490\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6934 - acc: 0.5210\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 30us/step - loss: 0.6886 - acc: 0.5420\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6886 - acc: 0.5450\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.6860 - acc: 0.5360\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 0.6906 - acc: 0.5330\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6873 - acc: 0.5230\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6862 - acc: 0.5490\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6868 - acc: 0.5480\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6873 - acc: 0.5250\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 34us/step - loss: 0.6841 - acc: 0.5580\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6860 - acc: 0.5470\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6844 - acc: 0.5580\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 0.6892 - acc: 0.5150\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6824 - acc: 0.5620\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6865 - acc: 0.5550\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6840 - acc: 0.5710\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6815 - acc: 0.5730\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.6809 - acc: 0.5640\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.6740 - acc: 0.578 - 0s 58us/step - loss: 0.6831 - acc: 0.5450\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.6862 - acc: 0.5620\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6799 - acc: 0.5480\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 0.6845 - acc: 0.5490\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6813 - acc: 0.5410\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6822 - acc: 0.5360\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6852 - acc: 0.5170\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6856 - acc: 0.5280\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 0.6799 - acc: 0.5720\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.6802 - acc: 0.5650\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6739 - acc: 0.5780\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6832 - acc: 0.5590\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6752 - acc: 0.5690\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6815 - acc: 0.5290\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6771 - acc: 0.5920\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.6726 - acc: 0.6040\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.6812 - acc: 0.5560\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.6774 - acc: 0.5850\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 59us/step - loss: 0.6763 - acc: 0.5790\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 49us/step - loss: 0.6774 - acc: 0.5690\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6718 - acc: 0.5920\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6735 - acc: 0.5620\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6745 - acc: 0.5850\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6770 - acc: 0.5510\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6670 - acc: 0.5990\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6662 - acc: 0.5950\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.6709 - acc: 0.6030\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 0.6707 - acc: 0.5890\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6783 - acc: 0.5580\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 38us/step - loss: 0.6736 - acc: 0.5770\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.6692 - acc: 0.5870\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6617 - acc: 0.5900\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6730 - acc: 0.5780\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 53us/step - loss: 0.6644 - acc: 0.6050\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6685 - acc: 0.5780\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 0.6657 - acc: 0.5920\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6632 - acc: 0.6090\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.6605 - acc: 0.6150\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6591 - acc: 0.5990\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6617 - acc: 0.5870\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 51us/step - loss: 0.6579 - acc: 0.6050\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6655 - acc: 0.5960\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 0.6615 - acc: 0.6090\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 0.6615 - acc: 0.5920\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 50us/step - loss: 0.6530 - acc: 0.6150\n",
      "100/100 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,\n",
    "         epochs=100,\n",
    "         batch_size=128)\n",
    "score = model.evaluate(x_test,y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
