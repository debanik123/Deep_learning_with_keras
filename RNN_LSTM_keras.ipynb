{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = [[[i+j] for i in range(5)] for j in range(100)]\n",
    "data = [[[(i+j)/100] for i in range(5)] for j in range(100)] #normalize\n",
    "#target = [(i+5) for i in range(100)]\n",
    "target = [(i+5)/100 for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data,dtype=float)\n",
    "target = np.array(target,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data,target,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 5, 1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences=True)) #fisrst one is number of o/p second one is input batch size\n",
    "model.add(LSTM((1),return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_absolute_error\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 5, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/500\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 0.5673 - acc: 0.0000e+00 - val_loss: 0.4557 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.5644 - acc: 0.0000e+00 - val_loss: 0.4529 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.5615 - acc: 0.0000e+00 - val_loss: 0.4500 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.5587 - acc: 0.0000e+00 - val_loss: 0.4472 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.5558 - acc: 0.0000e+00 - val_loss: 0.4443 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.5528 - acc: 0.0000e+00 - val_loss: 0.4414 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.5499 - acc: 0.0000e+00 - val_loss: 0.4384 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.5468 - acc: 0.0000e+00 - val_loss: 0.4354 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.5437 - acc: 0.0000e+00 - val_loss: 0.4323 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.5405 - acc: 0.0000e+00 - val_loss: 0.4291 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.5372 - acc: 0.0000e+00 - val_loss: 0.4258 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.5338 - acc: 0.0000e+00 - val_loss: 0.4224 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "80/80 [==============================] - 0s 747us/step - loss: 0.5304 - acc: 0.0000e+00 - val_loss: 0.4189 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.5268 - acc: 0.0000e+00 - val_loss: 0.4154 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.5231 - acc: 0.0000e+00 - val_loss: 0.4117 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.5194 - acc: 0.0000e+00 - val_loss: 0.4079 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.5155 - acc: 0.0000e+00 - val_loss: 0.4040 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.5114 - acc: 0.0000e+00 - val_loss: 0.3999 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.5073 - acc: 0.0000e+00 - val_loss: 0.3958 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "80/80 [==============================] - 0s 873us/step - loss: 0.5032 - acc: 0.0000e+00 - val_loss: 0.3915 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4989 - acc: 0.0000e+00 - val_loss: 0.3871 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4946 - acc: 0.0000e+00 - val_loss: 0.3826 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4902 - acc: 0.0000e+00 - val_loss: 0.3782 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4856 - acc: 0.0000e+00 - val_loss: 0.3738 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4808 - acc: 0.0000e+00 - val_loss: 0.3693 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4760 - acc: 0.0000e+00 - val_loss: 0.3647 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "80/80 [==============================] - 0s 960us/step - loss: 0.4712 - acc: 0.0000e+00 - val_loss: 0.3599 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4661 - acc: 0.0000e+00 - val_loss: 0.3550 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4611 - acc: 0.0000e+00 - val_loss: 0.3499 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4558 - acc: 0.0000e+00 - val_loss: 0.3448 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "80/80 [==============================] - 0s 860us/step - loss: 0.4507 - acc: 0.0000e+00 - val_loss: 0.3395 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4454 - acc: 0.0000e+00 - val_loss: 0.3341 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4402 - acc: 0.0000e+00 - val_loss: 0.3286 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "80/80 [==============================] - 0s 935us/step - loss: 0.4347 - acc: 0.0000e+00 - val_loss: 0.3229 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.4293 - acc: 0.0000e+00 - val_loss: 0.3171 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.4240 - acc: 0.0000e+00 - val_loss: 0.3111 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.4184 - acc: 0.0000e+00 - val_loss: 0.3051 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.4131 - acc: 0.0000e+00 - val_loss: 0.2993 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.4072 - acc: 0.0000e+00 - val_loss: 0.2937 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.4016 - acc: 0.0000e+00 - val_loss: 0.2879 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.3960 - acc: 0.0000e+00 - val_loss: 0.2819 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.3902 - acc: 0.0000e+00 - val_loss: 0.2759 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.3845 - acc: 0.0000e+00 - val_loss: 0.2704 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.3785 - acc: 0.0000e+00 - val_loss: 0.2655 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.3727 - acc: 0.0000e+00 - val_loss: 0.2604 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.3666 - acc: 0.0000e+00 - val_loss: 0.2557 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.3604 - acc: 0.0000e+00 - val_loss: 0.2513 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.3543 - acc: 0.0000e+00 - val_loss: 0.2469 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "80/80 [==============================] - 0s 822us/step - loss: 0.3483 - acc: 0.0000e+00 - val_loss: 0.2424 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "80/80 [==============================] - 0s 873us/step - loss: 0.3427 - acc: 0.0000e+00 - val_loss: 0.2379 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.3371 - acc: 0.0000e+00 - val_loss: 0.2339 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.3313 - acc: 0.0000e+00 - val_loss: 0.2301 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.3257 - acc: 0.0000e+00 - val_loss: 0.2263 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.3201 - acc: 0.0000e+00 - val_loss: 0.2225 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.3154 - acc: 0.0000e+00 - val_loss: 0.2191 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.3105 - acc: 0.0000e+00 - val_loss: 0.2163 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.3056 - acc: 0.0000e+00 - val_loss: 0.2136 - val_acc: 0.0000e+00\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 760us/step - loss: 0.3010 - acc: 0.0000e+00 - val_loss: 0.2117 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.2965 - acc: 0.0000e+00 - val_loss: 0.2098 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2920 - acc: 0.0000e+00 - val_loss: 0.2079 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.2881 - acc: 0.0000e+00 - val_loss: 0.2063 - val_acc: 0.0000e+00\n",
      "Epoch 62/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.2839 - acc: 0.0000e+00 - val_loss: 0.2051 - val_acc: 0.0000e+00\n",
      "Epoch 63/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.2800 - acc: 0.0000e+00 - val_loss: 0.2039 - val_acc: 0.0000e+00\n",
      "Epoch 64/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.2763 - acc: 0.0000e+00 - val_loss: 0.2027 - val_acc: 0.0000e+00\n",
      "Epoch 65/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2728 - acc: 0.0000e+00 - val_loss: 0.2015 - val_acc: 0.0000e+00\n",
      "Epoch 66/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.2696 - acc: 0.0000e+00 - val_loss: 0.2004 - val_acc: 0.0000e+00\n",
      "Epoch 67/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.2662 - acc: 0.0000e+00 - val_loss: 0.1993 - val_acc: 0.0000e+00\n",
      "Epoch 68/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.2636 - acc: 0.0000e+00 - val_loss: 0.1981 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.2608 - acc: 0.0000e+00 - val_loss: 0.1975 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2581 - acc: 0.0000e+00 - val_loss: 0.1970 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2557 - acc: 0.0000e+00 - val_loss: 0.1965 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.2530 - acc: 0.0000e+00 - val_loss: 0.1963 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.2509 - acc: 0.0000e+00 - val_loss: 0.1963 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2486 - acc: 0.0000e+00 - val_loss: 0.1962 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2464 - acc: 0.0000e+00 - val_loss: 0.1961 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.2444 - acc: 0.0000e+00 - val_loss: 0.1960 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "80/80 [==============================] - 0s 822us/step - loss: 0.2426 - acc: 0.0000e+00 - val_loss: 0.1959 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.2406 - acc: 0.0000e+00 - val_loss: 0.1957 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.2388 - acc: 0.0000e+00 - val_loss: 0.1956 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.2372 - acc: 0.0000e+00 - val_loss: 0.1956 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.2354 - acc: 0.0000e+00 - val_loss: 0.1956 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.2340 - acc: 0.0000e+00 - val_loss: 0.1956 - val_acc: 0.0500\n",
      "Epoch 83/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.2322 - acc: 0.0000e+00 - val_loss: 0.1954 - val_acc: 0.0500\n",
      "Epoch 84/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2307 - acc: 0.0000e+00 - val_loss: 0.1955 - val_acc: 0.0500\n",
      "Epoch 85/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.2293 - acc: 0.0000e+00 - val_loss: 0.1958 - val_acc: 0.0500\n",
      "Epoch 86/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.2277 - acc: 0.0000e+00 - val_loss: 0.1959 - val_acc: 0.0500\n",
      "Epoch 87/500\n",
      "80/80 [==============================] - 0s 772us/step - loss: 0.2262 - acc: 0.0000e+00 - val_loss: 0.1961 - val_acc: 0.0500\n",
      "Epoch 88/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.2247 - acc: 0.0000e+00 - val_loss: 0.1960 - val_acc: 0.0500\n",
      "Epoch 89/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2236 - acc: 0.0000e+00 - val_loss: 0.1958 - val_acc: 0.0500\n",
      "Epoch 90/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2222 - acc: 0.0000e+00 - val_loss: 0.1955 - val_acc: 0.0500\n",
      "Epoch 91/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.2210 - acc: 0.0000e+00 - val_loss: 0.1952 - val_acc: 0.0500\n",
      "Epoch 92/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.2199 - acc: 0.0000e+00 - val_loss: 0.1949 - val_acc: 0.0500\n",
      "Epoch 93/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.2188 - acc: 0.0000e+00 - val_loss: 0.1946 - val_acc: 0.0500\n",
      "Epoch 94/500\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.2176 - acc: 0.0000e+00 - val_loss: 0.1942 - val_acc: 0.0500\n",
      "Epoch 95/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.2164 - acc: 0.0000e+00 - val_loss: 0.1936 - val_acc: 0.0500\n",
      "Epoch 96/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2153 - acc: 0.0000e+00 - val_loss: 0.1930 - val_acc: 0.0500\n",
      "Epoch 97/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.2141 - acc: 0.0000e+00 - val_loss: 0.1923 - val_acc: 0.0500\n",
      "Epoch 98/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2130 - acc: 0.0000e+00 - val_loss: 0.1916 - val_acc: 0.0500\n",
      "Epoch 99/500\n",
      "80/80 [==============================] - 0s 836us/step - loss: 0.2118 - acc: 0.0000e+00 - val_loss: 0.1910 - val_acc: 0.0500\n",
      "Epoch 100/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2106 - acc: 0.0000e+00 - val_loss: 0.1902 - val_acc: 0.0500\n",
      "Epoch 101/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2094 - acc: 0.0000e+00 - val_loss: 0.1895 - val_acc: 0.0500\n",
      "Epoch 102/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.2082 - acc: 0.0000e+00 - val_loss: 0.1889 - val_acc: 0.0500\n",
      "Epoch 103/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2070 - acc: 0.0000e+00 - val_loss: 0.1881 - val_acc: 0.0500\n",
      "Epoch 104/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2057 - acc: 0.0000e+00 - val_loss: 0.1874 - val_acc: 0.0500\n",
      "Epoch 105/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.2045 - acc: 0.0000e+00 - val_loss: 0.1866 - val_acc: 0.0500\n",
      "Epoch 106/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.2031 - acc: 0.0000e+00 - val_loss: 0.1858 - val_acc: 0.0500\n",
      "Epoch 107/500\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.2019 - acc: 0.0000e+00 - val_loss: 0.1850 - val_acc: 0.0500\n",
      "Epoch 108/500\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.2005 - acc: 0.0000e+00 - val_loss: 0.1841 - val_acc: 0.0500\n",
      "Epoch 109/500\n",
      "80/80 [==============================] - 0s 698us/step - loss: 0.1992 - acc: 0.0000e+00 - val_loss: 0.1833 - val_acc: 0.0500\n",
      "Epoch 110/500\n",
      "80/80 [==============================] - 0s 873us/step - loss: 0.1979 - acc: 0.0000e+00 - val_loss: 0.1823 - val_acc: 0.0500\n",
      "Epoch 111/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.1965 - acc: 0.0000e+00 - val_loss: 0.1811 - val_acc: 0.0500\n",
      "Epoch 112/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.1951 - acc: 0.0000e+00 - val_loss: 0.1800 - val_acc: 0.0500\n",
      "Epoch 113/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.1938 - acc: 0.0000e+00 - val_loss: 0.1788 - val_acc: 0.0500\n",
      "Epoch 114/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.1923 - acc: 0.0000e+00 - val_loss: 0.1774 - val_acc: 0.0500\n",
      "Epoch 115/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.1909 - acc: 0.0000e+00 - val_loss: 0.1760 - val_acc: 0.0500\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 860us/step - loss: 0.1894 - acc: 0.0000e+00 - val_loss: 0.1746 - val_acc: 0.0500\n",
      "Epoch 117/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.1879 - acc: 0.0000e+00 - val_loss: 0.1732 - val_acc: 0.0500\n",
      "Epoch 118/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.1864 - acc: 0.0000e+00 - val_loss: 0.1718 - val_acc: 0.0500\n",
      "Epoch 119/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.1849 - acc: 0.0000e+00 - val_loss: 0.1704 - val_acc: 0.0500\n",
      "Epoch 120/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.1833 - acc: 0.0000e+00 - val_loss: 0.1691 - val_acc: 0.0500\n",
      "Epoch 121/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.1818 - acc: 0.0000e+00 - val_loss: 0.1678 - val_acc: 0.0500\n",
      "Epoch 122/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.1802 - acc: 0.0000e+00 - val_loss: 0.1665 - val_acc: 0.0500\n",
      "Epoch 123/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.1785 - acc: 0.0000e+00 - val_loss: 0.1649 - val_acc: 0.0500\n",
      "Epoch 124/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.1769 - acc: 0.0000e+00 - val_loss: 0.1633 - val_acc: 0.0500\n",
      "Epoch 125/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.1752 - acc: 0.0000e+00 - val_loss: 0.1617 - val_acc: 0.0500\n",
      "Epoch 126/500\n",
      "80/80 [==============================] - 0s 860us/step - loss: 0.1735 - acc: 0.0000e+00 - val_loss: 0.1600 - val_acc: 0.0500\n",
      "Epoch 127/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.1717 - acc: 0.0000e+00 - val_loss: 0.1581 - val_acc: 0.0500\n",
      "Epoch 128/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.1699 - acc: 0.0000e+00 - val_loss: 0.1561 - val_acc: 0.0500\n",
      "Epoch 129/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.1681 - acc: 0.0000e+00 - val_loss: 0.1542 - val_acc: 0.0500\n",
      "Epoch 130/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.1663 - acc: 0.0000e+00 - val_loss: 0.1525 - val_acc: 0.0500\n",
      "Epoch 131/500\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1644 - acc: 0.0000e+00 - val_loss: 0.1507 - val_acc: 0.0500\n",
      "Epoch 132/500\n",
      "80/80 [==============================] - 0s 948us/step - loss: 0.1624 - acc: 0.0000e+00 - val_loss: 0.1488 - val_acc: 0.0500\n",
      "Epoch 133/500\n",
      "80/80 [==============================] - 0s 885us/step - loss: 0.1605 - acc: 0.0000e+00 - val_loss: 0.1469 - val_acc: 0.0500\n",
      "Epoch 134/500\n",
      "80/80 [==============================] - 0s 972us/step - loss: 0.1586 - acc: 0.0000e+00 - val_loss: 0.1448 - val_acc: 0.0500\n",
      "Epoch 135/500\n",
      "80/80 [==============================] - 0s 772us/step - loss: 0.1565 - acc: 0.0000e+00 - val_loss: 0.1426 - val_acc: 0.0500\n",
      "Epoch 136/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.1545 - acc: 0.0000e+00 - val_loss: 0.1401 - val_acc: 0.0500\n",
      "Epoch 137/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.1523 - acc: 0.0000e+00 - val_loss: 0.1375 - val_acc: 0.0500\n",
      "Epoch 138/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.1502 - acc: 0.0000e+00 - val_loss: 0.1345 - val_acc: 0.0500\n",
      "Epoch 139/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.1481 - acc: 0.0000e+00 - val_loss: 0.1317 - val_acc: 0.0500\n",
      "Epoch 140/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.1459 - acc: 0.0000e+00 - val_loss: 0.1291 - val_acc: 0.0500\n",
      "Epoch 141/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.1436 - acc: 0.0000e+00 - val_loss: 0.1262 - val_acc: 0.0500\n",
      "Epoch 142/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.1414 - acc: 0.0000e+00 - val_loss: 0.1234 - val_acc: 0.0500\n",
      "Epoch 143/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.1391 - acc: 0.0000e+00 - val_loss: 0.1206 - val_acc: 0.0500\n",
      "Epoch 144/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.1367 - acc: 0.0000e+00 - val_loss: 0.1179 - val_acc: 0.0500\n",
      "Epoch 145/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.1342 - acc: 0.0000e+00 - val_loss: 0.1154 - val_acc: 0.0500\n",
      "Epoch 146/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.1317 - acc: 0.0000e+00 - val_loss: 0.1127 - val_acc: 0.0500\n",
      "Epoch 147/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.1293 - acc: 0.0000e+00 - val_loss: 0.1099 - val_acc: 0.0500\n",
      "Epoch 148/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.1266 - acc: 0.0000e+00 - val_loss: 0.1071 - val_acc: 0.0500\n",
      "Epoch 149/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.1239 - acc: 0.0000e+00 - val_loss: 0.1042 - val_acc: 0.0500\n",
      "Epoch 150/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.1211 - acc: 0.0000e+00 - val_loss: 0.1012 - val_acc: 0.0500\n",
      "Epoch 151/500\n",
      "80/80 [==============================] - 0s 747us/step - loss: 0.1185 - acc: 0.0000e+00 - val_loss: 0.0981 - val_acc: 0.0500\n",
      "Epoch 152/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.1156 - acc: 0.0000e+00 - val_loss: 0.0951 - val_acc: 0.0500\n",
      "Epoch 153/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.1126 - acc: 0.0000e+00 - val_loss: 0.0924 - val_acc: 0.0500\n",
      "Epoch 154/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.1097 - acc: 0.0000e+00 - val_loss: 0.0895 - val_acc: 0.0500\n",
      "Epoch 155/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.1068 - acc: 0.0000e+00 - val_loss: 0.0863 - val_acc: 0.0500\n",
      "Epoch 156/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.1038 - acc: 0.0000e+00 - val_loss: 0.0828 - val_acc: 0.0500\n",
      "Epoch 157/500\n",
      "80/80 [==============================] - 0s 860us/step - loss: 0.1006 - acc: 0.0000e+00 - val_loss: 0.0791 - val_acc: 0.0500\n",
      "Epoch 158/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0975 - acc: 0.0000e+00 - val_loss: 0.0753 - val_acc: 0.0500\n",
      "Epoch 159/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0942 - acc: 0.0000e+00 - val_loss: 0.0713 - val_acc: 0.0500\n",
      "Epoch 160/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0909 - acc: 0.0000e+00 - val_loss: 0.0672 - val_acc: 0.0500\n",
      "Epoch 161/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0875 - acc: 0.0000e+00 - val_loss: 0.0634 - val_acc: 0.0500\n",
      "Epoch 162/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0840 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0500\n",
      "Epoch 163/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0805 - acc: 0.0000e+00 - val_loss: 0.0559 - val_acc: 0.0500\n",
      "Epoch 164/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0770 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0500\n",
      "Epoch 165/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0738 - acc: 0.0000e+00 - val_loss: 0.0506 - val_acc: 0.0500\n",
      "Epoch 166/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0717 - acc: 0.0000e+00 - val_loss: 0.0499 - val_acc: 0.0500\n",
      "Epoch 167/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0502 - val_acc: 0.0500\n",
      "Epoch 168/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0676 - acc: 0.0000e+00 - val_loss: 0.0506 - val_acc: 0.0500\n",
      "Epoch 169/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0658 - acc: 0.0000e+00 - val_loss: 0.0509 - val_acc: 0.0500\n",
      "Epoch 170/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0643 - acc: 0.0000e+00 - val_loss: 0.0511 - val_acc: 0.0500\n",
      "Epoch 171/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.0629 - acc: 0.0000e+00 - val_loss: 0.0512 - val_acc: 0.0500\n",
      "Epoch 172/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0619 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0500\n",
      "Epoch 173/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0608 - acc: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.0500\n",
      "Epoch 174/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0601 - acc: 0.0000e+00 - val_loss: 0.0517 - val_acc: 0.0500\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 798us/step - loss: 0.0592 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0500\n",
      "Epoch 176/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0500\n",
      "Epoch 177/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0578 - acc: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.0500\n",
      "Epoch 178/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0570 - acc: 0.0000e+00 - val_loss: 0.0521 - val_acc: 0.0500\n",
      "Epoch 179/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0563 - acc: 0.0000e+00 - val_loss: 0.0520 - val_acc: 0.0500\n",
      "Epoch 180/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.0557 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0500\n",
      "Epoch 181/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0551 - acc: 0.0000e+00 - val_loss: 0.0517 - val_acc: 0.0500\n",
      "Epoch 182/500\n",
      "80/80 [==============================] - 0s 822us/step - loss: 0.0545 - acc: 0.0000e+00 - val_loss: 0.0516 - val_acc: 0.0500\n",
      "Epoch 183/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0539 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0500\n",
      "Epoch 184/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0533 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0500\n",
      "Epoch 185/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0528 - acc: 0.0000e+00 - val_loss: 0.0513 - val_acc: 0.0500\n",
      "Epoch 186/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0523 - acc: 0.0000e+00 - val_loss: 0.0513 - val_acc: 0.0500\n",
      "Epoch 187/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0518 - acc: 0.0000e+00 - val_loss: 0.0511 - val_acc: 0.0500\n",
      "Epoch 188/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0512 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0500\n",
      "Epoch 189/500\n",
      "80/80 [==============================] - 0s 836us/step - loss: 0.0508 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0500\n",
      "Epoch 190/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0504 - val_acc: 0.0500\n",
      "Epoch 191/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0498 - acc: 0.0000e+00 - val_loss: 0.0501 - val_acc: 0.0500\n",
      "Epoch 192/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0493 - acc: 0.0000e+00 - val_loss: 0.0497 - val_acc: 0.0500\n",
      "Epoch 193/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0500\n",
      "Epoch 194/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0490 - val_acc: 0.0500\n",
      "Epoch 195/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0480 - acc: 0.0000e+00 - val_loss: 0.0488 - val_acc: 0.0500\n",
      "Epoch 196/500\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.0476 - acc: 0.0000e+00 - val_loss: 0.0484 - val_acc: 0.0500\n",
      "Epoch 197/500\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.0471 - acc: 0.0000e+00 - val_loss: 0.0480 - val_acc: 0.0500\n",
      "Epoch 198/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0468 - acc: 0.0000e+00 - val_loss: 0.0475 - val_acc: 0.0500\n",
      "Epoch 199/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0463 - acc: 0.0000e+00 - val_loss: 0.0470 - val_acc: 0.0500\n",
      "Epoch 200/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0459 - acc: 0.0000e+00 - val_loss: 0.0466 - val_acc: 0.0500\n",
      "Epoch 201/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0455 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0500\n",
      "Epoch 202/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0451 - acc: 0.0000e+00 - val_loss: 0.0459 - val_acc: 0.0500\n",
      "Epoch 203/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0500\n",
      "Epoch 204/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0444 - acc: 0.0000e+00 - val_loss: 0.0453 - val_acc: 0.0500\n",
      "Epoch 205/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0441 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0500\n",
      "Epoch 206/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0493 - acc: 0.0000e+0 - 0s 811us/step - loss: 0.0437 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0500\n",
      "Epoch 207/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0443 - val_acc: 0.0500\n",
      "Epoch 208/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0429 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0500\n",
      "Epoch 209/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0500\n",
      "Epoch 210/500\n",
      "80/80 [==============================] - 0s 822us/step - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0500\n",
      "Epoch 211/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0419 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0500\n",
      "Epoch 212/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0429 - val_acc: 0.0500\n",
      "Epoch 213/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0500\n",
      "Epoch 214/500\n",
      "80/80 [==============================] - 0s 772us/step - loss: 0.0409 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0500\n",
      "Epoch 215/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0500\n",
      "Epoch 216/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0500\n",
      "Epoch 217/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0500\n",
      "Epoch 218/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0396 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0500\n",
      "Epoch 219/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0393 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0500\n",
      "Epoch 220/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
      "Epoch 221/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.0387 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0500\n",
      "Epoch 222/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0500\n",
      "Epoch 223/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0500\n",
      "Epoch 224/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0379 - acc: 0.0000e+00 - val_loss: 0.0398 - val_acc: 0.0500\n",
      "Epoch 225/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0500\n",
      "Epoch 226/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0500\n",
      "Epoch 227/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0500\n",
      "Epoch 228/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0500\n",
      "Epoch 229/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0500\n",
      "Epoch 230/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0500\n",
      "Epoch 231/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0500\n",
      "Epoch 232/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0500\n",
      "Epoch 233/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0500\n",
      "Epoch 235/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0351 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0500\n",
      "Epoch 236/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0500\n",
      "Epoch 237/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0500\n",
      "Epoch 238/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0345 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0500\n",
      "Epoch 239/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0500\n",
      "Epoch 240/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0500\n",
      "Epoch 241/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0500\n",
      "Epoch 242/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0500\n",
      "Epoch 243/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0500\n",
      "Epoch 244/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0500\n",
      "Epoch 245/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0500\n",
      "Epoch 246/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0500\n",
      "Epoch 247/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0326 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0500\n",
      "Epoch 248/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0324 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0500\n",
      "Epoch 249/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0322 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0500\n",
      "Epoch 250/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0500\n",
      "Epoch 251/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0500\n",
      "Epoch 252/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0500\n",
      "Epoch 253/500\n",
      "80/80 [==============================] - 0s 872us/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0500\n",
      "Epoch 254/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0500\n",
      "Epoch 255/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0500\n",
      "Epoch 256/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0500\n",
      "Epoch 257/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0500\n",
      "Epoch 258/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0500\n",
      "Epoch 259/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0500\n",
      "Epoch 260/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0500\n",
      "Epoch 261/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0500\n",
      "Epoch 262/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0500\n",
      "Epoch 263/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0500\n",
      "Epoch 264/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0500\n",
      "Epoch 265/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0500\n",
      "Epoch 266/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0500\n",
      "Epoch 267/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0500\n",
      "Epoch 268/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0500\n",
      "Epoch 269/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0500\n",
      "Epoch 270/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0500\n",
      "Epoch 271/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0500\n",
      "Epoch 272/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0500\n",
      "Epoch 273/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0500\n",
      "Epoch 274/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0500\n",
      "Epoch 275/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0500\n",
      "Epoch 276/500\n",
      "80/80 [==============================] - 0s 772us/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0500\n",
      "Epoch 277/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0500\n",
      "Epoch 278/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0500\n",
      "Epoch 279/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0500\n",
      "Epoch 280/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0500\n",
      "Epoch 281/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0500\n",
      "Epoch 282/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0500\n",
      "Epoch 283/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0500\n",
      "Epoch 284/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0500\n",
      "Epoch 285/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0500\n",
      "Epoch 286/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0500\n",
      "Epoch 287/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0500\n",
      "Epoch 288/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0500\n",
      "Epoch 289/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0500\n",
      "Epoch 290/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0500\n",
      "Epoch 291/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0500\n",
      "Epoch 292/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0500\n",
      "Epoch 294/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0500\n",
      "Epoch 295/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0500\n",
      "Epoch 296/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0500\n",
      "Epoch 297/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0500\n",
      "Epoch 298/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0500\n",
      "Epoch 299/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0500\n",
      "Epoch 300/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0500\n",
      "Epoch 301/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0500\n",
      "Epoch 302/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0500\n",
      "Epoch 303/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0500\n",
      "Epoch 304/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0500\n",
      "Epoch 305/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0500\n",
      "Epoch 306/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0500\n",
      "Epoch 307/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0500\n",
      "Epoch 308/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0500\n",
      "Epoch 309/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0500\n",
      "Epoch 310/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0500\n",
      "Epoch 311/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0500\n",
      "Epoch 312/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0500\n",
      "Epoch 313/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0262 - val_acc: 0.0500\n",
      "Epoch 314/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0500\n",
      "Epoch 315/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0500\n",
      "Epoch 316/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0232 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0500\n",
      "Epoch 317/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0232 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0500\n",
      "Epoch 318/500\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0500\n",
      "Epoch 319/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0500\n",
      "Epoch 320/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0259 - val_acc: 0.0500\n",
      "Epoch 321/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0500\n",
      "Epoch 322/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0261 - val_acc: 0.0500\n",
      "Epoch 323/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0500\n",
      "Epoch 324/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0500\n",
      "Epoch 325/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0225 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0500\n",
      "Epoch 326/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0224 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0500\n",
      "Epoch 327/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0500\n",
      "Epoch 328/500\n",
      "80/80 [==============================] - 0s 724us/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0500\n",
      "Epoch 329/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0500\n",
      "Epoch 330/500\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0250 - val_acc: 0.0500\n",
      "Epoch 331/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0500\n",
      "Epoch 332/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0500\n",
      "Epoch 333/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0219 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0500\n",
      "Epoch 334/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0218 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0500\n",
      "Epoch 335/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0500\n",
      "Epoch 336/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0500\n",
      "Epoch 337/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0500\n",
      "Epoch 338/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0500\n",
      "Epoch 339/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0500\n",
      "Epoch 340/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0214 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0500\n",
      "Epoch 341/500\n",
      "80/80 [==============================] - 0s 822us/step - loss: 0.0214 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0500\n",
      "Epoch 342/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0203 - acc: 0.0000e+0 - 0s 761us/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0246 - val_acc: 0.0500\n",
      "Epoch 343/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0500\n",
      "Epoch 344/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0500\n",
      "Epoch 345/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0500\n",
      "Epoch 346/500\n",
      "80/80 [==============================] - 0s 772us/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0236 - val_acc: 0.0500\n",
      "Epoch 347/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0500\n",
      "Epoch 348/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0500\n",
      "Epoch 349/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0209 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0500\n",
      "Epoch 350/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0500\n",
      "Epoch 351/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 798us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0500\n",
      "Epoch 352/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0500\n",
      "Epoch 353/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0206 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 354/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0500\n",
      "Epoch 355/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0234 - val_acc: 0.0500\n",
      "Epoch 356/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0205 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0500\n",
      "Epoch 357/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0239 - val_acc: 0.0500\n",
      "Epoch 358/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0237 - val_acc: 0.0500\n",
      "Epoch 359/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 360/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0500\n",
      "Epoch 361/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 362/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 363/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0500\n",
      "Epoch 364/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0233 - val_acc: 0.0500\n",
      "Epoch 365/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0500\n",
      "Epoch 366/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0199 - acc: 0.0000e+00 - val_loss: 0.0227 - val_acc: 0.0500\n",
      "Epoch 367/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0500\n",
      "Epoch 368/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0500\n",
      "Epoch 369/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0500\n",
      "Epoch 370/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 371/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0500\n",
      "Epoch 372/500\n",
      "80/80 [==============================] - 0s 747us/step - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0500\n",
      "Epoch 373/500\n",
      "80/80 [==============================] - 0s 848us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.0500\n",
      "Epoch 374/500\n",
      "80/80 [==============================] - 0s 836us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 375/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 376/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0500\n",
      "Epoch 377/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0227 - val_acc: 0.0500\n",
      "Epoch 378/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0195 - acc: 0.0000e+00 - val_loss: 0.0227 - val_acc: 0.0500\n",
      "Epoch 379/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0195 - acc: 0.0000e+00 - val_loss: 0.0224 - val_acc: 0.0500\n",
      "Epoch 380/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0195 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 381/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0223 - val_acc: 0.0500\n",
      "Epoch 382/500\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 383/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0500\n",
      "Epoch 384/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0500\n",
      "Epoch 385/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0500\n",
      "Epoch 386/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0500\n",
      "Epoch 387/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0500\n",
      "Epoch 388/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 389/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 390/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 391/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0500\n",
      "Epoch 392/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0500\n",
      "Epoch 393/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0500\n",
      "Epoch 394/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0500\n",
      "Epoch 395/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 396/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 397/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 398/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 399/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0500\n",
      "Epoch 400/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0217 - val_acc: 0.0500\n",
      "Epoch 401/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0500\n",
      "Epoch 402/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0500\n",
      "Epoch 403/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0500\n",
      "Epoch 404/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0500\n",
      "Epoch 405/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0500\n",
      "Epoch 406/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0214 - val_acc: 0.0500\n",
      "Epoch 407/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 408/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0500\n",
      "Epoch 409/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0500\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 760us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0500\n",
      "Epoch 411/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0500\n",
      "Epoch 412/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0218 - val_acc: 0.0500\n",
      "Epoch 413/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0500\n",
      "Epoch 414/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0207 - val_acc: 0.0500\n",
      "Epoch 415/500\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 416/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 417/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 418/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0500\n",
      "Epoch 419/500\n",
      "80/80 [==============================] - 0s 772us/step - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0500\n",
      "Epoch 420/500\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0500\n",
      "Epoch 421/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 422/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 423/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 424/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 425/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0182 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0500\n",
      "Epoch 426/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0182 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 427/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0500\n",
      "Epoch 428/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0500\n",
      "Epoch 429/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 430/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 431/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0207 - val_acc: 0.0500\n",
      "Epoch 432/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 433/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n",
      "Epoch 434/500\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 435/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0179 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 436/500\n",
      "80/80 [==============================] - 0s 711us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0500\n",
      "Epoch 437/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0180 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0500\n",
      "Epoch 438/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0179 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 439/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 440/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 441/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 442/500\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0188 - acc: 0.0000e+0 - 0s 736us/step - loss: 0.0179 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 443/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 444/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 445/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 446/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 447/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 448/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 449/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0207 - val_acc: 0.0500\n",
      "Epoch 450/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0178 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0500\n",
      "Epoch 451/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 452/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 453/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 454/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0176 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 455/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n",
      "Epoch 456/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0500\n",
      "Epoch 457/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0204 - val_acc: 0.0500\n",
      "Epoch 458/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 459/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 460/500\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 461/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 462/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 463/500\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 464/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 465/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 466/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 467/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0173 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 468/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0175 - acc: 0.0000e+00 - val_loss: 0.0207 - val_acc: 0.0500\n",
      "Epoch 470/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 471/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 472/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0500\n",
      "Epoch 473/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 474/500\n",
      "80/80 [==============================] - 0s 836us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 475/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 476/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 477/500\n",
      "80/80 [==============================] - 0s 749us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 478/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 479/500\n",
      "80/80 [==============================] - 0s 810us/step - loss: 0.0172 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 480/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0500\n",
      "Epoch 481/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 482/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0500\n",
      "Epoch 483/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0500\n",
      "Epoch 484/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0500\n",
      "Epoch 485/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 486/500\n",
      "80/80 [==============================] - 0s 785us/step - loss: 0.0171 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n",
      "Epoch 487/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0500\n",
      "Epoch 488/500\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 489/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0500\n",
      "Epoch 490/500\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 491/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 492/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0500\n",
      "Epoch 493/500\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 494/500\n",
      "80/80 [==============================] - 0s 748us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0500\n",
      "Epoch 495/500\n",
      "80/80 [==============================] - 0s 823us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 496/500\n",
      "80/80 [==============================] - 0s 786us/step - loss: 0.0169 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0500\n",
      "Epoch 497/500\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.0168 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0500\n",
      "Epoch 498/500\n",
      "80/80 [==============================] - 0s 736us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 499/500\n",
      "80/80 [==============================] - 0s 761us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0500\n",
      "Epoch 500/500\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),results,c=\"r\")\n",
    "plt.scatter(range(20),y_test,c=\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
